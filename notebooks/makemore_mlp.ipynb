{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('../data/names.txt').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary and mappings\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build dataset\n",
    "\n",
    "def build_dataset(words):\n",
    "    block_size = 3 # content length: how many characters to predict next one\n",
    "    x, y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            x.append(context)\n",
    "            y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y)\n",
    "    print(x.shape, y.shape)\n",
    "    return x, y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "xtr, ytr = build_dataset(words[:n1])\n",
    "xdev, ydev = build_dataset(words[n1:n2])\n",
    "xte, yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([182625, 3]), torch.Size([182625]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtr.shape, ytr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 200\n",
    "vocab_size = 27\n",
    "block_size = 3\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "c = torch.randn((vocab_size, n_embd), generator=g)\n",
    "w1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.01\n",
    "w2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.01\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0\n",
    "bngain = torch.ones((1, n_hidden))\n",
    "bnbias = torch.zeros((1, n_hidden))\n",
    "bnmean_running = torch.zeros((1, n_hidden))\n",
    "bnstd_running = torch.ones((1, n_hidden))\n",
    "parameters = [c, w1, b1, w2, b2, bngain, bnbias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12297"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # total parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.296679973602295\n"
     ]
    }
   ],
   "source": [
    "stepi = []\n",
    "lossi = []\n",
    "stepi = []\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "\n",
    "for i in range(max_steps):\n",
    "    # minibatch\n",
    "    ix = torch.randint(0, xtr.shape[0], (batch_size,))\n",
    "    \n",
    "    # forward pass\n",
    "    emb = c[xtr[ix]]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ w1 + b1 # hidden layer pre-activation\n",
    "    bnmeani = hpreact.mean(0, keepdim=True)\n",
    "    bnstdi = hpreact.std(0, keepdim=True)\n",
    "    hpreact = bngain * (hpreact - bnmeani) / bnstdi + bnbias # Batch Normalization - (preactivations - mean)/variance then scale and shift\n",
    "    \n",
    "    # estimate batch norm post-training values\n",
    "    with torch.no_grad():\n",
    "        bnmean_running = 0.999 * bnmean_running + 0.001 * bnmeani\n",
    "        bnstd_running = 0.999 * bnstd_running + 0.001 * bnstdi\n",
    "    \n",
    "    h = torch.tanh(hpreact) # 32, 100\n",
    "    logits = h @ w2 + b2 # 32, 27\n",
    "    loss = F.cross_entropy(logits, ytr[ix])\n",
    "    #print(loss.item())\n",
    "    \n",
    "    # backward\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    \n",
    "    # stats\n",
    "    stepi.append(i)\n",
    "    lossi.append(loss.log10().item())\n",
    "    \n",
    "    #break\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19fbb7adf88>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.1066744327545166\n",
      "val 2.1066744327545166\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # disable gradient tracking\n",
    "def split_loss(split):\n",
    "    x, y ={\n",
    "        'train': (xtr, ytr),\n",
    "        'val': (xdev, ydev),\n",
    "        'test': (xte, yte)\n",
    "    }[split]\n",
    "    emb = c[xdev]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ w1 + b1\n",
    "    hpreact = bngain * (hpreact - bnmean_running) / bnstd_running + bnbias\n",
    "    h = torch.tanh(hpreact) # 32, 100\n",
    "    logits = h @ w2 + b2 # 32, 27\n",
    "    loss = F.cross_entropy(logits, ydev)\n",
    "    print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carlavela.\n",
      "jhavi.\n",
      "kimri.\n",
      "rehtyn.\n",
      "kanden.\n",
      "jazonte.\n",
      "delynn.\n",
      "jareei.\n",
      "nellara.\n",
      "chaiir.\n",
      "kaleigh.\n",
      "ham.\n",
      "joce.\n",
      "quinthorocken.\n",
      "jadiquinte.\n",
      "madiaryxia.\n",
      "kael.\n",
      "dusti.\n",
      "edde.\n",
      "oia.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        emb = c[torch.tensor([context])]\n",
    "        embcat = emb.view(emb.shape[0], -1)\n",
    "        hpreact = embcat @ w1 + b1\n",
    "        hpreact = bngain * (hpreact - bnmean_running) / bnstd_running + bnbias\n",
    "        h = torch.tanh(hpreact) # 32, 100\n",
    "        logits = h @ w2 + b2 # 32, 27\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prettifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out), generator=g) / fan_in**0.5\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm1d:\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # forward pass\n",
    "        if self.training:\n",
    "            xmean = x.mean(0, keepdim=True) # batch mean\n",
    "            xvar = x.var(0, keepdim=True) # batch variance\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        \n",
    "        # update buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "n_embd = 10 # embedding dimensionality\n",
    "n_hidden = 100 # number of neruons in hidden layer\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "vocab_size = 27 # letters + stop char\n",
    "block_size = 3 # context size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46924\n"
     ]
    }
   ],
   "source": [
    "c = torch.randn((vocab_size, n_embd), generator=g)\n",
    "net = [\n",
    "    Linear(n_embd * block_size, n_hidden), Tanh(),\n",
    "    Linear(n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size, bias=False), BatchNorm1d(vocab_size)\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    # make last layer less confident\n",
    "    net[-1].gamma *= 0.1\n",
    "    # all other layers apply gain\n",
    "    for layer in net[:-1]:\n",
    "        if isinstance(layer, Linear):\n",
    "            layer.weight *= 5/3\n",
    "\n",
    "parameters = [c] + [p for layer in net for p in layer.parameters()] # add embedding layer and get parameters\n",
    "print(sum(p.nelement() for p in parameters)) # print number of total parameters\n",
    "for p in parameters:\n",
    "    p.requires_grad = True # enable gradient tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.2880\n",
      "  10000/ 200000: 2.3139\n",
      "  20000/ 200000: 2.0990\n",
      "  30000/ 200000: 1.9273\n",
      "  40000/ 200000: 2.1110\n",
      "  50000/ 200000: 2.1956\n",
      "  60000/ 200000: 1.7521\n",
      "  70000/ 200000: 2.1468\n",
      "  80000/ 200000: 2.2422\n",
      "  90000/ 200000: 1.7301\n",
      " 100000/ 200000: 2.3226\n",
      " 110000/ 200000: 2.1911\n",
      " 120000/ 200000: 2.0660\n",
      " 130000/ 200000: 1.8067\n",
      " 140000/ 200000: 1.7208\n",
      " 150000/ 200000: 1.8728\n",
      " 160000/ 200000: 2.0226\n",
      " 170000/ 200000: 1.9664\n",
      " 180000/ 200000: 2.2835\n",
      " 190000/ 200000: 1.9255\n"
     ]
    }
   ],
   "source": [
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "    # batch data\n",
    "    ix = torch.randint(0, xtr.shape[0], (batch_size,), generator=g) # random index\n",
    "    xb, yb = xtr[ix], ytr[ix]\n",
    "    \n",
    "    # forward pass\n",
    "    emb = c[xb] # embed characters into vectors\n",
    "    x = emb.view(emb.shape[0], -1) # concat vectors\n",
    "    for layer in net:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x, yb)\n",
    "    \n",
    "    # back pass\n",
    "    for layer in net:\n",
    "        layer.out.retain_grad()\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update weights\n",
    "    lr = 0.1 if i < 100000 else 0.01 # learning rate + decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    \n",
    "    # track stats\n",
    "    if i % 10000 == 0:\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.001737594604492\n",
      "val 2.0836873054504395\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "@ torch.no_grad()\n",
    "def split_loss(split):\n",
    "    x, y = {\n",
    "        'train': (xtr, ytr),\n",
    "        'val': (xdev, ydev),\n",
    "        'test': (xte, yte)\n",
    "    }[split]\n",
    "    emb = c[x]\n",
    "    x = emb.view(emb.shape[0], -1)\n",
    "    for layer in net:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x, y)\n",
    "    print(split, loss.item())\n",
    "\n",
    "# put net into eval mode\n",
    "for layer in net:\n",
    "    layer.training = False\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carlah.\n",
      "amillivia.\n",
      "jari.\n",
      "reety.\n",
      "skaan.\n",
      "kenleigh.\n",
      "farelynn.\n",
      "kaeli.\n",
      "nellara.\n",
      "chaiivon.\n",
      "legend.\n",
      "bron.\n",
      "catessan.\n",
      "shon.\n",
      "rai.\n",
      "addicia.\n",
      "elo.\n",
      "dearisia.\n",
      "kaellissa.\n",
      "mel.\n"
     ]
    }
   ],
   "source": [
    "# sample model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        # forward pass through the net\n",
    "        emb = c[torch.tensor([context])]\n",
    "        x = emb.view(emb.shape[0], -1)\n",
    "        for layer in net:\n",
    "            x = layer(x)\n",
    "        logits = x\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        # sample from dist\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        # shift context window\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
